{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion PP_EDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOOTGaEeEVnjcPG68X/JXDO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DSookarah/CE888_Assignment/blob/main/Emotion_PP_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "Pd6WlbJm7X7N",
        "outputId": "ed8f8a68-cbb2-4d65-8c7f-84db5a75900e"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "# For visualizations\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "# For regular expressions\r\n",
        "import re\r\n",
        "# For handling string\r\n",
        "import string\r\n",
        "# For performing mathematical operations\r\n",
        "import math\r\n",
        "\r\n",
        "# Importing dataset\r\n",
        "df=pd.read_csv('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/emotion/test_text.txt', delimiter='\\t') \r\n",
        "\r\n",
        "print(\"Shape of data=>\",df.shape)\r\n",
        "\r\n",
        "df.columns=['Em']\r\n",
        "\r\n",
        "df.head(10)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data=> (1420, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Em</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user Interesting choice of words... Are you c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My visit to hospital for care triggered #traum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user Welcome to #MPSVT! We are delighted to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What makes you feel #joyful?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am revolting.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Rin might ever appeared gloomy but to be a mel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>In need of a change! #restless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>@user @user #cmbyn does screen  August 4 &amp;amp;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@user Get Donovan out of your soccer booth. He...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@user how can u have sold so many copies but u...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Em\n",
              "0  @user Interesting choice of words... Are you c...\n",
              "1  My visit to hospital for care triggered #traum...\n",
              "2  @user Welcome to #MPSVT! We are delighted to h...\n",
              "3                      What makes you feel #joyful? \n",
              "4                                   i am revolting. \n",
              "5  Rin might ever appeared gloomy but to be a mel...\n",
              "6                    In need of a change! #restless \n",
              "7  @user @user #cmbyn does screen  August 4 &amp;...\n",
              "8  @user Get Donovan out of your soccer booth. He...\n",
              "9  @user how can u have sold so many copies but u..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfDrvi8OCWX6"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKw_l_4eDx7v",
        "outputId": "32bab449-0845-4cef-c944-5ffd919ed967"
      },
      "source": [
        "# Dictionary of English Contractions\r\n",
        "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\r\n",
        "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\r\n",
        "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\r\n",
        "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\r\n",
        "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\r\n",
        "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\r\n",
        "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\r\n",
        "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\r\n",
        "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\r\n",
        "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\r\n",
        "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\r\n",
        "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\r\n",
        "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \r\n",
        "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\r\n",
        "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\r\n",
        "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\r\n",
        "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\r\n",
        "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\r\n",
        "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\r\n",
        "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\r\n",
        "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\r\n",
        "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\r\n",
        "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\r\n",
        "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\r\n",
        "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\r\n",
        "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\r\n",
        "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\r\n",
        "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\r\n",
        "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\r\n",
        "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\r\n",
        "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\r\n",
        "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\r\n",
        "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\r\n",
        "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\r\n",
        "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\r\n",
        "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\r\n",
        "                     \"you've\": \"you have\"}\r\n",
        "\r\n",
        "\r\n",
        "# Regular expression for finding contractions\r\n",
        "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\r\n",
        "\r\n",
        "# Function for expanding contractions\r\n",
        "def expand_contractions(text,contractions_dict=contractions_dict):\r\n",
        "  def replace(match):\r\n",
        "    return contractions_dict[match.group(0)]\r\n",
        "  return contractions_re.sub(replace, text)\r\n",
        "\r\n",
        "# Expanding Contractions in the reviews\r\n",
        "df['Em']=df['Em'].apply(lambda x:expand_contractions(x))\r\n",
        "\r\n",
        "df.iloc[8]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Em    @user Get Donovan out of your soccer booth. He...\n",
              "Name: 8, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "iI7YwyX5Firn"
      },
      "source": [
        "df['cleaned']=df['Em'].apply(lambda x: x.lower())"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kgmrQDLLuy2"
      },
      "source": [
        "df['cleaned']=df['cleaned'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0-KtJscL8cB"
      },
      "source": [
        "df['cleaned']=df['cleaned'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtVXUa4VMkbY"
      },
      "source": [
        "# Importing spacy\r\n",
        "import spacy\r\n",
        "\r\n",
        "# Loading model\r\n",
        "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\r\n",
        "\r\n",
        "# Lemmatization with stopwords removal\r\n",
        "df['lemmatized']=df['cleaned'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "GQ1oHle1LwhG",
        "outputId": "d05c3bc9-17bb-4044-8acb-baa3feb1baed"
      },
      "source": [
        "df.head(15)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Em</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user Interesting choice of words... Are you c...</td>\n",
              "      <td>user interesting choice of words are you confi...</td>\n",
              "      <td>user interesting choice word confirm governmen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My visit to hospital for care triggered #traum...</td>\n",
              "      <td>my visit to hospital for care triggered trauma...</td>\n",
              "      <td>visit hospital care trigger trauma accident yr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user Welcome to #MPSVT! We are delighted to h...</td>\n",
              "      <td>user welcome to mpsvt we are delighted to have...</td>\n",
              "      <td>user welcome mpsvt delighted grateful mpsvt re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What makes you feel #joyful?</td>\n",
              "      <td>what makes you feel joyful</td>\n",
              "      <td>make feel joyful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am revolting.</td>\n",
              "      <td>i am revolting</td>\n",
              "      <td>revolt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Rin might ever appeared gloomy but to be a mel...</td>\n",
              "      <td>rin might ever appeared gloomy but to be a mel...</td>\n",
              "      <td>rin appear gloomy melodramatic person thingnnb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>In need of a change! #restless</td>\n",
              "      <td>in need of a change restless</td>\n",
              "      <td>need change restless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>@user @user #cmbyn does screen  August 4 &amp;amp;...</td>\n",
              "      <td>user user cmbyn does screen  august  amp  at m...</td>\n",
              "      <td>user user cmbyn screen   august   amp   miff</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@user Get Donovan out of your soccer booth. He...</td>\n",
              "      <td>user get donovan out of your soccer booth hes ...</td>\n",
              "      <td>user donovan soccer booth s awful s bitter mak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@user how can u have sold so many copies but u...</td>\n",
              "      <td>user how can u have sold so many copies but ur...</td>\n",
              "      <td>user u sell copy ur game fucking bug mad lag i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Pressured. üò¶</td>\n",
              "      <td>pressured üò¶</td>\n",
              "      <td>pressured üò¶</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Yes #depression &amp;amp; #anxiety are real but so...</td>\n",
              "      <td>yes depression amp anxiety are real but so is ...</td>\n",
              "      <td>yes depression amp anxiety real bein grateful ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>People who say nmu are the worst, something ha...</td>\n",
              "      <td>people who say nmu are the worst something has...</td>\n",
              "      <td>people nmu bad go tell wanna know bout life s ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>@user The hatred from the Left ought to concer...</td>\n",
              "      <td>user the hatred from the left ought to concern...</td>\n",
              "      <td>user hatred left ought concern everyonewho wan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>@user #shocking loss of talented young man#pra...</td>\n",
              "      <td>user shocking loss of talented young manprayer...</td>\n",
              "      <td>user shocking loss talented young manprayerspr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Em  ...                                         lemmatized\n",
              "0   @user Interesting choice of words... Are you c...  ...  user interesting choice word confirm governmen...\n",
              "1   My visit to hospital for care triggered #traum...  ...  visit hospital care trigger trauma accident yr...\n",
              "2   @user Welcome to #MPSVT! We are delighted to h...  ...  user welcome mpsvt delighted grateful mpsvt re...\n",
              "3                       What makes you feel #joyful?   ...                                   make feel joyful\n",
              "4                                    i am revolting.   ...                                             revolt\n",
              "5   Rin might ever appeared gloomy but to be a mel...  ...  rin appear gloomy melodramatic person thingnnb...\n",
              "6                     In need of a change! #restless   ...                               need change restless\n",
              "7   @user @user #cmbyn does screen  August 4 &amp;...  ...       user user cmbyn screen   august   amp   miff\n",
              "8   @user Get Donovan out of your soccer booth. He...  ...  user donovan soccer booth s awful s bitter mak...\n",
              "9   @user how can u have sold so many copies but u...  ...  user u sell copy ur game fucking bug mad lag i...\n",
              "10                                      Pressured. üò¶   ...                                        pressured üò¶\n",
              "11  Yes #depression &amp; #anxiety are real but so...  ...  yes depression amp anxiety real bein grateful ...\n",
              "12  People who say nmu are the worst, something ha...  ...  people nmu bad go tell wanna know bout life s ...\n",
              "13  @user The hatred from the Left ought to concer...  ...  user hatred left ought concern everyonewho wan...\n",
              "14  @user #shocking loss of talented young man#pra...  ...  user shocking loss talented young manprayerspr...\n",
              "\n",
              "[15 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "SYQLRmFwOFPg",
        "outputId": "35d1ba96-2ca4-4302-927e-92e7634f2727"
      },
      "source": [
        "df_grouped=df[['Em','lemmatized']].groupby(by='Em').agg(lambda x:' '.join(x))\r\n",
        "df_grouped.head()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Em</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>#ATO hacking into your phone calls and text messages! #privacylaws #invasion I knew they did it but hearing them get approval !</th>\n",
              "      <td>ato hack phone call text message privacylaw in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>#AmarnathTerrorAttack  Muslims are killing everywhere Syria Iraq Palestine Everyday beyond They say that Islam is terrorism shame on you</th>\n",
              "      <td>amarnathterrorattack   muslims kill syria iraq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>#AmarnathTerrorAttack @user @user cn u plz ans wt u r afrd of or wt stpng u to end #terrorism wn whol #India is stndng wth u</th>\n",
              "      <td>amarnathterrorattack user user cn u plz ans wt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>#AmarnathTerrorAttack saddened to hear this ....need to take strict action against #terrorism ...</th>\n",
              "      <td>amarnathterrorattack sadden hear need strict a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>#Amazon's #PrimeDay debut in #India was #disappointing, maybe next year it will get better..glad it's finally here though! üòÖ</th>\n",
              "      <td>amazons primeday debut india disappoint maybe ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                           lemmatized\n",
              "Em                                                                                                   \n",
              "#ATO hacking into your phone calls and text mes...  ato hack phone call text message privacylaw in...\n",
              "#AmarnathTerrorAttack  Muslims are killing ever...  amarnathterrorattack   muslims kill syria iraq...\n",
              "#AmarnathTerrorAttack @user @user cn u plz ans ...  amarnathterrorattack user user cn u plz ans wt...\n",
              "#AmarnathTerrorAttack saddened to hear this ......  amarnathterrorattack sadden hear need strict a...\n",
              "#Amazon's #PrimeDay debut in #India was #disapp...  amazons primeday debut india disappoint maybe ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "hllnUyCLOVjn",
        "outputId": "bc681944-84c9-4851-ce4d-b416310bf170"
      },
      "source": [
        "\r\n",
        "# Creating Document Term Matrix\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer \r\n",
        "cv=CountVectorizer(analyzer='word')\r\n",
        "data=cv.fit_transform(df_grouped['lemmatized'])\r\n",
        "df_dtm = pd.DataFrame(data.toarray(), columns=cv.get_feature_names())\r\n",
        "df_dtm.index=df_grouped.index\r\n",
        "df_dtm.head(3)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaaaaaaaaagh</th>\n",
              "      <th>aaron</th>\n",
              "      <th>abdl</th>\n",
              "      <th>ability</th>\n",
              "      <th>abit</th>\n",
              "      <th>able</th>\n",
              "      <th>abolish</th>\n",
              "      <th>abomination</th>\n",
              "      <th>abortion</th>\n",
              "      <th>abraham</th>\n",
              "      <th>abrasion</th>\n",
              "      <th>abroad</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>abt</th>\n",
              "      <th>abuelito</th>\n",
              "      <th>abuse</th>\n",
              "      <th>abuser</th>\n",
              "      <th>ac</th>\n",
              "      <th>accept</th>\n",
              "      <th>access</th>\n",
              "      <th>accessibility</th>\n",
              "      <th>accident</th>\n",
              "      <th>accidentally</th>\n",
              "      <th>accom</th>\n",
              "      <th>accompany</th>\n",
              "      <th>accomplish</th>\n",
              "      <th>accordingly</th>\n",
              "      <th>account</th>\n",
              "      <th>accountable</th>\n",
              "      <th>ache</th>\n",
              "      <th>achieverni</th>\n",
              "      <th>acknowledge</th>\n",
              "      <th>acrylics</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>active</th>\n",
              "      <th>activity</th>\n",
              "      <th>actor</th>\n",
              "      <th>actorslife</th>\n",
              "      <th>actress</th>\n",
              "      <th>...</th>\n",
              "      <th>yell</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yen</th>\n",
              "      <th>yeon</th>\n",
              "      <th>yep</th>\n",
              "      <th>yer</th>\n",
              "      <th>yes</th>\n",
              "      <th>yessss</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yett</th>\n",
              "      <th>yike</th>\n",
              "      <th>yip</th>\n",
              "      <th>yoongi</th>\n",
              "      <th>you</th>\n",
              "      <th>youaregoingdown</th>\n",
              "      <th>youndarkerside</th>\n",
              "      <th>young</th>\n",
              "      <th>youni</th>\n",
              "      <th>younjust</th>\n",
              "      <th>younproduction</th>\n",
              "      <th>youth</th>\n",
              "      <th>yoyo</th>\n",
              "      <th>yoyonyoyo</th>\n",
              "      <th>yrs</th>\n",
              "      <th>yuko</th>\n",
              "      <th>yukwon</th>\n",
              "      <th>yummy</th>\n",
              "      <th>yummymummiesau</th>\n",
              "      <th>zany</th>\n",
              "      <th>zayuuumbeys</th>\n",
              "      <th>ze</th>\n",
              "      <th>zhat</th>\n",
              "      <th>zhe</th>\n",
              "      <th>zico</th>\n",
              "      <th>zima</th>\n",
              "      <th>zion</th>\n",
              "      <th>√∂land</th>\n",
              "      <th>Áõ∏‰∫í„Éï„Ç©„É≠„Éº</th>\n",
              "      <th>ÎãàÍ∞ÄÌïòÎ©¥</th>\n",
              "      <th>ÎçîÏáº</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Em</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>#ATO hacking into your phone calls and text messages! #privacylaws #invasion I knew they did it but hearing them get approval !</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>#AmarnathTerrorAttack  Muslims are killing everywhere Syria Iraq Palestine Everyday beyond They say that Islam is terrorism shame on you</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>#AmarnathTerrorAttack @user @user cn u plz ans wt u r afrd of or wt stpng u to end #terrorism wn whol #India is stndng wth u</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows √ó 4305 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    aaaaaaaaaagh  ...  ÎçîÏáº\n",
              "Em                                                                ...    \n",
              "#ATO hacking into your phone calls and text mes...             0  ...   0\n",
              "#AmarnathTerrorAttack  Muslims are killing ever...             0  ...   0\n",
              "#AmarnathTerrorAttack @user @user cn u plz ans ...             0  ...   0\n",
              "\n",
              "[3 rows x 4305 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "B9bbusoxNSKH",
        "outputId": "acf6a2e9-5c88-4e65-a41c-b60f145428de"
      },
      "source": [
        "# Importing wordcloud for plotting word clouds and textwrap for wrapping longer text\r\n",
        "from wordcloud import WordCloud\r\n",
        "from textwrap import wrap\r\n",
        "\r\n",
        "# Function for generating word clouds\r\n",
        "def generate_wordcloud(data,title):\r\n",
        "  wc = WordCloud(width=400, height=330, max_words=150,colormap=\"Dark2\").generate_from_frequencies(data)\r\n",
        "  plt.figure(figsize=(10,8))\r\n",
        "  plt.imshow(wc, interpolation='bilinear')\r\n",
        "  plt.axis(\"off\")\r\n",
        "  plt.title('\\n'.join(wrap(title,60)),fontsize=13)\r\n",
        "  plt.show()\r\n",
        "  \r\n",
        "# Transposing document term matrix\r\n",
        "df_dtm=df_dtm.transpose()\r\n",
        "\r\n",
        "# Plotting word cloud for each product\r\n",
        "for index,product in enumerate(df_dtm.columns):\r\n",
        "  generate_wordcloud(df_dtm[product].sort_values(ascending=False),product)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-09db7eea20be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Plotting word cloud for each product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproduct\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mgenerate_wordcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dtm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-72-09db7eea20be>\u001b[0m in \u001b[0;36mgenerate_wordcloud\u001b[0;34m(data, title)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Function for generating word clouds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_wordcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mwc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m330\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Dark2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 font_size = int(round((rs * (freq / float(last_freq))\n\u001b[0m\u001b[1;32m    465\u001b[0m                                        + (1 - rs)) * font_size))\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefer_horizontal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ]
    }
  ]
}